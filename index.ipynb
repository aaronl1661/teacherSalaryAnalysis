{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final Tutorial: Analysis of Professor Performance at UMD\n",
    "Collaborators: Albert Chen, Alex Chen, Aaron Lin, Srujan Penikelapati"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Table of Contents\n",
    "\n",
    "* [Introduction](#introduction)\n",
    "* [Step 1: Data Collection](#data-collection)\n",
    "    * [Imports](#imports)\n",
    "    * [PlanetTerp](#planetterp)\n",
    "    * [Diamondback](#diamondback)\n",
    "    * [Combining PlanetTerp Data](#combining-planetterp-data)\n",
    "* [Step 2: Data Cleaning](#data-cleaning)\n",
    "    * [Duplicates in Diamondback](#duplicates-in-diamondback)\n",
    "    * [Matching Names](#matching-names)\n",
    "    * [Getting Departments](#getting-departments)\n",
    "    * [Missing Professors](#missing-professors)\n",
    "    * [Professors with Missing Years](#professors-with-missing-years)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction <a class=\"anchor\" id = \"introduction\"></a>\n",
    "\n",
    "Data science is an interdisciplinary field that involves the collection, cleaning, visualization, analysis, and interpretation of complex data sets. The ultimate goal of data science is to extract meaningful and actionable insights from data that can inform decision-making, and improve outcomes across a variety of industries. In this tutorial, we will using a data science project of our own to guide the reader through the data science lifecycle, which is listed above in the Table of Contents. \n",
    "\n",
    "Faculty are the lifeblood of any university. They conduct cutting-edge research to discover new insights that push the boundary of the field they are studying. They also teach classes, helping students learn new skills and knowledge that will benefit them in their professional lives. As in any occupation, professors vary in the quality of their research and their teaching ability. This directly impacts the quality of education that students who take their classes receive. Students understand this clearly and will spend hours looking for the right professor that will give them an engaging and informative semester.\n",
    "\n",
    "This is why we decided to analyze the effectiveness of professors at UMD. The analysis done in the project can answer questions that administrators and students have on the state of professors at UMD. For example, a UMD administrator might want to know whether a professor with a high salary and many years of experience at UMD teaches better than other professors. A student might be faced with picking between two professors teaching the same course, and want to know which one would would help them get a better GPA.\n",
    "\n",
    "To analyze the effectiveness of the professors, we decided to look at two independent variables: the number of years they've been teaching and the salary that they get paid. The dependent variable, effectiveness, will be measured by the professors' GPAs (Grade Point Average) and the student reviews. These two variables indicate how well the students understood the information, along with how effectively the professor taught a course."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"sheena_sheep.png\" alt=\"Sheena_Sheep\" />"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Collection <a class=\"anchor\" id = \"data-collection\"></a>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data collection is the first and most critical step in the data science process. It involves gathering and organizing data from various sources. One popular method of collecting data is through GET requests, which are used to retrieve data from web applications via the HTTPS protocol. However, this process can be time consuming, as large amounts of data are being sent over the internet, so this data is downloaded and stored locally for us to use."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports <a class=\"anchor\" id = \"imports\"></a>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These are the various libraries that will be used throughout the course of this tutorial. This project utilizes Python and Jupyter notebook, with a majority of the data manipulation being done through the [Pandas](https://pandas.pydata.org/) library. This library is  one the most important and frequently used libraries in this tutorial, as it allows us to store data in dataframes. These dataframes are similar to 2D matricies or tables, and the Pandas library has many built in functions that makes data manipulation efficient and effective. The various other libraries help us retrieve, manage, and analyze our data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "import os\n",
    "from pathlib import Path\n",
    "import os.path\n",
    "from statsmodels.formula.api import *\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import linear_model\n",
    "from ggplot import *\n",
    "import numpy as np\n",
    "import ast\n",
    "from bs4 import BeautifulSoup\n",
    "from IPython.display import clear_output, display, HTML"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Collection: PlanetTerp <a class=\"anchor\" id = \"planetterp\"></a>\n",
    "\n",
    "Since we are looking for information on a professor's grade distributions, student reviews of that professor, and the number of years a professor has been teaching, [PlanetTerp](https://planetterp.com/) was a natural place to look for the information we needed. The data there is specific to UMD and the website itself was made by students, who were generous enough to provide us a [documented API](https://planetterp.com/api/) that we could use. We used GET requests to the PlanetTerp API in order to get the information from the website, before storing it into dataframes. However, we quickly discovered that performing all of these requests could take excessive amounts of time. As such, we decided to store our data into csv files and then read from those files locally rather than constantly re-requesting the website. We did this by checking if our csv files already existed, and if they did we could simply read from those files, only requesting from the site if the csv files we were looking for didn't exist. As such, all of the data used from here on out in this tutorial will be accurate up until April 28th, 2023, as that is the last time we actually requested information from PlanetTerp itself. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews_exist = os.path.exists(\"src/1_collect_data/planet_terp_data/PT_review_data.csv\")\n",
    "grades_exist = os.path.exists(\"src/1_collect_data/planet_terp_data/PT_grade_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "if reviews_exist == False:\n",
    "    reviews = []\n",
    "    done = False\n",
    "    offset = 0\n",
    "    # maximum limit is 100, keep requesting until all of the data has been collected\n",
    "    while done == False:\n",
    "        r = requests.get(\"https://planetterp.com/api/v1/professors\", params = {\"offset\":offset, \"reviews\": \"true\", \"limit\":100},)\n",
    "        if r.json() == []:\n",
    "            done = True\n",
    "        else:\n",
    "            reviews.append(r.json())\n",
    "            offset = offset+100\n",
    "    df = pd.DataFrame()\n",
    "    count = 0\n",
    "    # separate out data, each review gets its own row\n",
    "    for i in reviews:\n",
    "        for j in i:\n",
    "            if j.get(\"reviews\") != []:\n",
    "                for k in j.get(\"reviews\"):\n",
    "                    # only add review if it is for a professor, not a TA, and there is a course attached to it\n",
    "                    if k.get(\"course\") != None and j.get(\"type\") == \"professor\":\n",
    "                        df.at[count, \"name\"] = j.get(\"name\")\n",
    "                        df.at[count, \"slug\"] = j.get(\"slug\")\n",
    "                        df.at[count, \"type\"] = j.get(\"type\")\n",
    "                        df.at[count, \"course\"] = k.get(\"course\")\n",
    "                        df.at[count, \"rating\"] = k.get(\"rating\")\n",
    "                        df.at[count, \"review\"] = k.get(\"review\")\n",
    "                        df.at[count, \"date\"] = k.get(\"created\")[:10]\n",
    "                        count = count + 1\n",
    "\n",
    "    df = df.sort_values(by=[\"name\",\"course\"])\n",
    "    df.to_csv(\"src/1_collect_data/PT_review_data.csv\", encoding='utf-8', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "if grades_exist == False:\n",
    "    offset = 0\n",
    "    grades = []\n",
    "    professors = df[\"name\"].drop_duplicates()\n",
    "    # get grade data for each professor\n",
    "    for prof in professors:\n",
    "        r = requests.get(\"https://planetterp.com/api/v1/grades\", params = {\"offset\":offset, \"reviews\": \"true\", \"limit\":100, \"professor\": prof})\n",
    "        grades.append(r.json())\n",
    "    grade_df = pd.DataFrame()\n",
    "    count = 0\n",
    "    # each semester of each course gets its own row in the dataframe\n",
    "    for i in grades:\n",
    "        if i != []:\n",
    "            for j in i:\n",
    "                grade_df.at[count, \"professor\"] = j.get(\"professor\")\n",
    "                grade_df.at[count, \"course\"] = j.get(\"course\")\n",
    "                grade_df.at[count, \"semester\"] = j.get(\"semester\")\n",
    "                grade_df.at[count, \"section\"] = j.get(\"section\")\n",
    "                grade_df.at[count, \"A+\"] = j.get(\"A+\")\n",
    "                grade_df.at[count, \"A\"] = j.get(\"A\")\n",
    "                grade_df.at[count, \"A-\"] = j.get(\"A-\")\n",
    "                grade_df.at[count, \"B+\"] = j.get(\"B+\")\n",
    "                grade_df.at[count, \"B\"] = j.get(\"B\")\n",
    "                grade_df.at[count, \"B-\"] = j.get(\"B-\")\n",
    "                grade_df.at[count, \"C+\"] = j.get(\"C+\")\n",
    "                grade_df.at[count, \"C\"] = j.get(\"C\")\n",
    "                grade_df.at[count, \"C-\"] = j.get(\"C-\")\n",
    "                grade_df.at[count, \"D+\"] = j.get(\"D+\")\n",
    "                grade_df.at[count, \"D\"] = j.get(\"D\")\n",
    "                grade_df.at[count, \"D-\"] = j.get(\"D-\")\n",
    "                grade_df.at[count, \"F\"] = j.get(\"F\")\n",
    "                grade_df.at[count, \"W\"] = j.get(\"W\")\n",
    "                grade_df.at[count, \"Other\"] = j.get(\"Other\")\n",
    "                count = count + 1\n",
    "    \n",
    "    grade_df = grade_df.sort_values(by=[\"professor\",\"course\"])\n",
    "    grade_df.to_csv(\"src/1_collect_data/PT_grade_data.csv\", encoding = \"utf-8\", index = False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Diamondback <a class=\"anchor\" id = \"diamondback\"></a>\n",
    "\n",
    "The other information that we need is a way to find out how much a teacher is earning at the University of Maryland. [The Diamondback](https://dbknews.com/) published a [salary guide](https://salaryguide.dbknews.com/) in 2022, which has its own [API](https://api.dbknews.com/docs/#/salary). From here, we were then able to perform the same process of using GET requests to read the salary data for each year from 2013 to 2022. However, it was slightly more complicated, since the API would only show the salary data one page (10 entries) at a time. We also performed the same procedure of writing our data to csv files to read from locally, as all of these requests also took very long to perform. The data used from here on out is accurate up until 2022."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "salaries_exist = os.path.exists(\"src/1_collect_data/salary_data/DB_combined_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine(group):\n",
    "    years = group['year'].tolist()\n",
    "    salaries = group['Salary'].tolist()\n",
    "    salaries = [float(s.replace(\",\",\"\")[1:]) for s in salaries]\n",
    "    departments = group['Department'].tolist()\n",
    "    \n",
    "    i = 0\n",
    "    while i < len(years) - 1:\n",
    "        if (years[i] == years[i+1]):\n",
    "            if salaries[i] != salaries[i + 1]:\n",
    "                salaries[i] = salaries[i] + salaries[i + 1]\n",
    "            years.pop(i+1)\n",
    "            salaries.pop(i+1)\n",
    "            departments.pop(i+1)\n",
    "        else:\n",
    "            i += 1\n",
    "\n",
    "    return pd.Series({\n",
    "        'years_taught': years,\n",
    "        'salaries': salaries,\n",
    "        'departments': departments,\n",
    "    })\n",
    "\n",
    "if salaries_exist == False:\n",
    "    # get years that api is valid for\n",
    "    r_years = requests.get(\"https://api.dbknews.com/salary/years\")\n",
    "    years = r_years.json()[\"data\"]\n",
    "\n",
    "    df = pd.DataFrame()\n",
    "\n",
    "    # for each year, get salary data\n",
    "    for year in years:\n",
    "        r = requests.get(f\"https://api.dbknews.com/salary/year/{year}\")\n",
    "\n",
    "        # number of faculty\n",
    "        count = r.json()[\"count\"]\n",
    "        year_df = pd.DataFrame()\n",
    "        page = 0\n",
    "\n",
    "        while page * 10 < count:\n",
    "            page += 1\n",
    "\n",
    "            # get salary data for 1 page\n",
    "            r = requests.get(f\"https://api.dbknews.com/salary/year/{year}?page={page}\")\n",
    "            page_df = pd.DataFrame.from_dict(r.json()[\"data\"])\n",
    "\n",
    "            # remove division and title columns, modify department col, and add year\n",
    "            page_df = page_df.drop(['Division', \"Title\"], axis=1)\n",
    "            page_df[\"Department\"] = page_df[\"Department\"].str.slice(stop=4)\n",
    "            page_df[\"year\"] = [f\"{year}\"] * len(page_df.index)\n",
    "            year_df = pd.concat([year_df, page_df], axis=0)\n",
    "\n",
    "        print(f\"year {year} finished\")\n",
    "        year_df.to_csv(f'src/1_collect_data/salary_data/{year}data.csv', index=False)\n",
    "\n",
    "    # get data for all of the years into one dataframe\n",
    "    for year in years:\n",
    "        year_df = pd.read_csv(f'src/1_collect_data/salary_data/{year}data.csv')\n",
    "        year_df['Employee'] = year_df['Employee'].str.replace('\\n', ' ')\n",
    "        df = pd.concat([df, year_df], axis=0)\n",
    "\n",
    "    # combine all of the information for a single professor into one row\n",
    "    df_grouped = df.groupby(['Employee']).apply(combine).reset_index()\n",
    "\n",
    "    df_grouped['name'] = df_grouped['Employee'].apply(lambda x: (x.split(', ')[1].split(\" \")[0]+ ' ' + x.split(', ')[0].split(\" \")[-1]).upper())\n",
    "\n",
    "    df_grouped.to_csv(f'src/1_collect_data/salary_data/DB_combined_data.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews_df = pd.read_csv(\"src/1_collect_data/planet_terp_data/PT_review_data.csv\")\n",
    "grades_df = pd.read_csv(\"src/1_collect_data/planet_terp_data/PT_grade_data.csv\")\n",
    "salaries_df = pd.read_csv(\"src/1_collect_data/salary_data/DB_combined_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>slug</th>\n",
       "      <th>type</th>\n",
       "      <th>course</th>\n",
       "      <th>rating</th>\n",
       "      <th>review</th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A Anthony</td>\n",
       "      <td>anthony</td>\n",
       "      <td>professor</td>\n",
       "      <td>AMST203</td>\n",
       "      <td>1.0</td>\n",
       "      <td>By far the worst professor I’ve ever had, and ...</td>\n",
       "      <td>2018-08-17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A Kruglanski</td>\n",
       "      <td>kruglanski</td>\n",
       "      <td>professor</td>\n",
       "      <td>PSYC489H</td>\n",
       "      <td>2.0</td>\n",
       "      <td>DO NOT TAKE PSYC489H \"Motivated Social Cogniti...</td>\n",
       "      <td>2015-09-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A Sharma</td>\n",
       "      <td>sharma_a</td>\n",
       "      <td>professor</td>\n",
       "      <td>ASTR300</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Very boring, it's hard to maintain your focus ...</td>\n",
       "      <td>2019-04-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A Sharma</td>\n",
       "      <td>sharma_a</td>\n",
       "      <td>professor</td>\n",
       "      <td>ASTR300</td>\n",
       "      <td>1.0</td>\n",
       "      <td>You'll pass but this class will be the most bo...</td>\n",
       "      <td>2019-05-26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A Sharma</td>\n",
       "      <td>sharma_a</td>\n",
       "      <td>professor</td>\n",
       "      <td>ASTR300</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Rather difficult course. Class is extremely bo...</td>\n",
       "      <td>2019-12-08</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           name        slug       type    course  rating  \\\n",
       "0     A Anthony     anthony  professor   AMST203     1.0   \n",
       "1  A Kruglanski  kruglanski  professor  PSYC489H     2.0   \n",
       "2      A Sharma    sharma_a  professor   ASTR300     2.0   \n",
       "3      A Sharma    sharma_a  professor   ASTR300     1.0   \n",
       "4      A Sharma    sharma_a  professor   ASTR300     1.0   \n",
       "\n",
       "                                              review        date  \n",
       "0  By far the worst professor I’ve ever had, and ...  2018-08-17  \n",
       "1  DO NOT TAKE PSYC489H \"Motivated Social Cogniti...  2015-09-07  \n",
       "2  Very boring, it's hard to maintain your focus ...  2019-04-04  \n",
       "3  You'll pass but this class will be the most bo...  2019-05-26  \n",
       "4  Rather difficult course. Class is extremely bo...  2019-12-08  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviews_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>professor</th>\n",
       "      <th>course</th>\n",
       "      <th>semester</th>\n",
       "      <th>section</th>\n",
       "      <th>A+</th>\n",
       "      <th>A</th>\n",
       "      <th>A-</th>\n",
       "      <th>B+</th>\n",
       "      <th>B</th>\n",
       "      <th>B-</th>\n",
       "      <th>C+</th>\n",
       "      <th>C</th>\n",
       "      <th>C-</th>\n",
       "      <th>D+</th>\n",
       "      <th>D</th>\n",
       "      <th>D-</th>\n",
       "      <th>F</th>\n",
       "      <th>W</th>\n",
       "      <th>Other</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A Anthony</td>\n",
       "      <td>AMST202</td>\n",
       "      <td>201608</td>\n",
       "      <td>0101</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A Anthony</td>\n",
       "      <td>AMST202</td>\n",
       "      <td>201701</td>\n",
       "      <td>0101</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A Anthony</td>\n",
       "      <td>AMST203</td>\n",
       "      <td>201708</td>\n",
       "      <td>FCH1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A Anthony</td>\n",
       "      <td>AMST203</td>\n",
       "      <td>201708</td>\n",
       "      <td>FCH2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A Anthony</td>\n",
       "      <td>AMST203</td>\n",
       "      <td>201801</td>\n",
       "      <td>0201</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   professor   course  semester section   A+    A   A-   B+    B   B-   C+  \\\n",
       "0  A Anthony  AMST202    201608    0101  1.0  2.0  1.0  2.0  5.0  1.0  2.0   \n",
       "1  A Anthony  AMST202    201701    0101  0.0  1.0  4.0  3.0  3.0  7.0  3.0   \n",
       "2  A Anthony  AMST203    201708    FCH1  0.0  2.0  1.0  1.0  6.0  2.0  1.0   \n",
       "3  A Anthony  AMST203    201708    FCH2  0.0  0.0  1.0  4.0  3.0  0.0  0.0   \n",
       "4  A Anthony  AMST203    201801    0201  1.0  3.0  1.0  2.0  4.0  0.0  2.0   \n",
       "\n",
       "     C   C-   D+    D   D-    F    W  Other  \n",
       "0  3.0  5.0  0.0  0.0  0.0  2.0  4.0    0.0  \n",
       "1  2.0  0.0  0.0  0.0  0.0  0.0  1.0    1.0  \n",
       "2  0.0  0.0  0.0  0.0  0.0  0.0  4.0    0.0  \n",
       "3  4.0  1.0  1.0  0.0  1.0  0.0  2.0    0.0  \n",
       "4  3.0  1.0  0.0  0.0  2.0  2.0  6.0    0.0  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grades_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Employee</th>\n",
       "      <th>years_taught</th>\n",
       "      <th>salaries</th>\n",
       "      <th>departments</th>\n",
       "      <th>name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A Karim, Eaman</td>\n",
       "      <td>[2018, 2019]</td>\n",
       "      <td>[48000.0, 48960.0]</td>\n",
       "      <td>['ENGR', 'ENGR']</td>\n",
       "      <td>EAMAN KARIM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A'Hearn, Michael F.</td>\n",
       "      <td>[2013, 2014, 2015, 2016, 2017]</td>\n",
       "      <td>[125817.0, 130849.69, 145530.01, 155925.01, 13...</td>\n",
       "      <td>['CMNS', 'CMNS', 'CMNS', 'CMNS', 'CMNS']</td>\n",
       "      <td>MICHAEL A'HEARN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AMIN, MOHAMMED NURUL</td>\n",
       "      <td>[2015]</td>\n",
       "      <td>[46500.0]</td>\n",
       "      <td>['CMNS']</td>\n",
       "      <td>MOHAMMED AMIN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Aarhus, William H</td>\n",
       "      <td>[2016, 2017, 2018, 2019, 2020, 2021, 2022]</td>\n",
       "      <td>[75000.0, 75750.0, 75750.0, 77265.0, 80780.68,...</td>\n",
       "      <td>['SVPA', 'SVPA', 'SVPA', 'SVPA', 'SVPA', 'EXST...</td>\n",
       "      <td>WILLIAM AARHUS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Abadi, Berhane</td>\n",
       "      <td>[2022]</td>\n",
       "      <td>[31278.0]</td>\n",
       "      <td>['VPSA']</td>\n",
       "      <td>BERHANE ABADI</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Employee                                years_taught  \\\n",
       "0        A Karim, Eaman                                [2018, 2019]   \n",
       "1   A'Hearn, Michael F.              [2013, 2014, 2015, 2016, 2017]   \n",
       "2  AMIN, MOHAMMED NURUL                                      [2015]   \n",
       "3     Aarhus, William H  [2016, 2017, 2018, 2019, 2020, 2021, 2022]   \n",
       "4        Abadi, Berhane                                      [2022]   \n",
       "\n",
       "                                            salaries  \\\n",
       "0                                 [48000.0, 48960.0]   \n",
       "1  [125817.0, 130849.69, 145530.01, 155925.01, 13...   \n",
       "2                                          [46500.0]   \n",
       "3  [75000.0, 75750.0, 75750.0, 77265.0, 80780.68,...   \n",
       "4                                          [31278.0]   \n",
       "\n",
       "                                         departments             name  \n",
       "0                                   ['ENGR', 'ENGR']      EAMAN KARIM  \n",
       "1           ['CMNS', 'CMNS', 'CMNS', 'CMNS', 'CMNS']  MICHAEL A'HEARN  \n",
       "2                                           ['CMNS']    MOHAMMED AMIN  \n",
       "3  ['SVPA', 'SVPA', 'SVPA', 'SVPA', 'SVPA', 'EXST...   WILLIAM AARHUS  \n",
       "4                                           ['VPSA']    BERHANE ABADI  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "salaries_df.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Combining PlanetTerp Data <a class=\"anchor\" id = \"combining-planetterp-data\"></a>\n",
    "\n",
    "Eventually, we would like to have all of our data come together into one single dataframe for us to manipulate. Since student reviews and grades are currently being stored in separate dataframes, the first step towards our end goal is logically to combine these two dataframes into one, as they both come from the same data source. We would like to separate all of the data we currently have, grouping them by a specific course taught by a specific professor in a specific semester. The grade data from PlanetTerp is stored in this format, with each professor's classes being separated out into every semester they taught the class. However, the reviews left on the website don't have the semester that the student took the class in listed. As such, we have to make assumptions for what semester a student took the class they are reviewing based on the date that they left their review. We assume any review left from September to December are for fall classes, January are for winter classes, February to May are for spring classes, and June to August are for summer classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>slug</th>\n",
       "      <th>type</th>\n",
       "      <th>course</th>\n",
       "      <th>rating</th>\n",
       "      <th>review</th>\n",
       "      <th>date</th>\n",
       "      <th>year</th>\n",
       "      <th>season</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A Anthony</td>\n",
       "      <td>anthony</td>\n",
       "      <td>professor</td>\n",
       "      <td>AMST203</td>\n",
       "      <td>1.0</td>\n",
       "      <td>By far the worst professor I’ve ever had, and ...</td>\n",
       "      <td>2018-08-17</td>\n",
       "      <td>2018</td>\n",
       "      <td>summer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A Kruglanski</td>\n",
       "      <td>kruglanski</td>\n",
       "      <td>professor</td>\n",
       "      <td>PSYC489H</td>\n",
       "      <td>2.0</td>\n",
       "      <td>DO NOT TAKE PSYC489H \"Motivated Social Cogniti...</td>\n",
       "      <td>2015-09-07</td>\n",
       "      <td>2015</td>\n",
       "      <td>fall</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A Sharma</td>\n",
       "      <td>sharma_a</td>\n",
       "      <td>professor</td>\n",
       "      <td>ASTR300</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Very boring, it's hard to maintain your focus ...</td>\n",
       "      <td>2019-04-04</td>\n",
       "      <td>2019</td>\n",
       "      <td>spring</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A Sharma</td>\n",
       "      <td>sharma_a</td>\n",
       "      <td>professor</td>\n",
       "      <td>ASTR300</td>\n",
       "      <td>1.0</td>\n",
       "      <td>You'll pass but this class will be the most bo...</td>\n",
       "      <td>2019-05-26</td>\n",
       "      <td>2019</td>\n",
       "      <td>spring</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A Sharma</td>\n",
       "      <td>sharma_a</td>\n",
       "      <td>professor</td>\n",
       "      <td>ASTR300</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Rather difficult course. Class is extremely bo...</td>\n",
       "      <td>2019-12-08</td>\n",
       "      <td>2019</td>\n",
       "      <td>fall</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           name        slug       type    course  rating  \\\n",
       "0     A Anthony     anthony  professor   AMST203     1.0   \n",
       "1  A Kruglanski  kruglanski  professor  PSYC489H     2.0   \n",
       "2      A Sharma    sharma_a  professor   ASTR300     2.0   \n",
       "3      A Sharma    sharma_a  professor   ASTR300     1.0   \n",
       "4      A Sharma    sharma_a  professor   ASTR300     1.0   \n",
       "\n",
       "                                              review        date  year  season  \n",
       "0  By far the worst professor I’ve ever had, and ...  2018-08-17  2018  summer  \n",
       "1  DO NOT TAKE PSYC489H \"Motivated Social Cogniti...  2015-09-07  2015    fall  \n",
       "2  Very boring, it's hard to maintain your focus ...  2019-04-04  2019  spring  \n",
       "3  You'll pass but this class will be the most bo...  2019-05-26  2019  spring  \n",
       "4  Rather difficult course. Class is extremely bo...  2019-12-08  2019    fall  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for index, row in reviews_df.iterrows():\n",
    "    reviews_df.at[index, \"year\"] = str(reviews_df.at[index, \"date\"])[:4]\n",
    "    #getting the month from date formatted as YYYY-MM-DD\n",
    "    if int(str(reviews_df.at[index, \"date\"])[5:7]) > 8:\n",
    "        reviews_df.at[index, \"season\"] = \"fall\"\n",
    "    elif str(reviews_df.at[index, \"date\"])[5:7] == \"01\":\n",
    "        reviews_df.at[index, \"season\"] = \"winter\"\n",
    "    elif str(reviews_df.at[index, \"date\"])[5:7] == \"06\" or str(reviews_df.at[index, \"date\"])[5:7] == \"07\" or str(reviews_df.at[index, \"date\"])[5:7] == \"08\" :\n",
    "        reviews_df.at[index, \"season\"] = \"summer\"\n",
    "    else:\n",
    "        reviews_df.at[index, \"season\"] = \"spring\"\n",
    "\n",
    "reviews_df.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then group all of the reviews for a certain professor's class that were detected to be from the same semester together, averaging out the ratings for that semester."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>course</th>\n",
       "      <th>year</th>\n",
       "      <th>season</th>\n",
       "      <th>average_rating</th>\n",
       "      <th>num_reviews</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A Anthony</td>\n",
       "      <td>AMST203</td>\n",
       "      <td>2018</td>\n",
       "      <td>summer</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A Kruglanski</td>\n",
       "      <td>PSYC489H</td>\n",
       "      <td>2015</td>\n",
       "      <td>fall</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A Sharma</td>\n",
       "      <td>ASTR300</td>\n",
       "      <td>2019</td>\n",
       "      <td>fall</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A Sharma</td>\n",
       "      <td>ASTR300</td>\n",
       "      <td>2019</td>\n",
       "      <td>spring</td>\n",
       "      <td>1.5</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A Sharma</td>\n",
       "      <td>ASTR300</td>\n",
       "      <td>2020</td>\n",
       "      <td>fall</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           name    course  year  season  average_rating  num_reviews\n",
       "0     A Anthony   AMST203  2018  summer             1.0          1.0\n",
       "1  A Kruglanski  PSYC489H  2015    fall             2.0          1.0\n",
       "2      A Sharma   ASTR300  2019    fall             1.0          1.0\n",
       "3      A Sharma   ASTR300  2019  spring             1.5          2.0\n",
       "4      A Sharma   ASTR300  2020    fall             2.0          1.0"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sort by the following to ensure that reviews corresponding to the same semester get grouped together\n",
    "reviews_df = reviews_df.sort_values(by = [\"name\", \"course\", \"year\", \"season\"], ignore_index = True)\n",
    "\n",
    "average_reviews_df = pd.DataFrame()\n",
    "\n",
    "values_to_check = [\"name\", \"course\", \"year\", \"season\"]\n",
    "curr = [reviews_df.at[0, \"name\"], reviews_df.at[0, \"course\"], reviews_df.at[0, \"year\"], reviews_df.at[0, \"season\"]]\n",
    "count = 0\n",
    "averages = [0, 0]\n",
    "for index, row in reviews_df.iterrows():\n",
    "    match = True\n",
    "    # see if the next row in the dataframe is for the current semester\n",
    "    for i in range(4):\n",
    "        if curr[i] != reviews_df.at[index, values_to_check[i]]:\n",
    "            match = False\n",
    "    if not match:\n",
    "        # once it is not a match, write the current accumulated information to the dataframe and reset\n",
    "        for i in range(4):\n",
    "            average_reviews_df.at[count, values_to_check[i]] = curr[i]\n",
    "            curr[i] = reviews_df.at[index, values_to_check[i]]\n",
    "        average_reviews_df.at[count, \"average_rating\"] = averages[0]/averages[1]\n",
    "        average_reviews_df.at[count, \"num_reviews\"] = averages[1]\n",
    "        count = count + 1\n",
    "        averages = [0, 0]\n",
    "    averages[0] = averages[0] + reviews_df.at[index, \"rating\"]\n",
    "    averages[1] = averages[1] + 1\n",
    "# add in the last row\n",
    "for i in range(4):\n",
    "    average_reviews_df.at[count, values_to_check[i]] = curr[i]\n",
    "average_reviews_df.at[count, \"average_rating\"] = averages[0]/averages[1]\n",
    "average_reviews_df.at[count, \"num_reviews\"] = averages[1]\n",
    "\n",
    "average_reviews_df.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The semester information for grades are stored implicitly on PlanetTerp. The format is year, followed by either 08 or 01, corresponding to either fall or spring semester. For example, grade information for the fall 2021 semester would be stored under the tag of 202108. As such, we can extract this information and continue with the same process as above, grouping grades from semesters that are the same together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, row in grades_df.iterrows():\n",
    "    grades_df.at[index, \"year\"] = str(grades_df.at[index, \"semester\"])[:4]\n",
    "    if str(grades_df.at[index, \"semester\"])[4:] == \"08\":\n",
    "        grades_df.at[index, \"season\"] = \"fall\"\n",
    "    else:\n",
    "        grades_df.at[index, \"season\"] = \"spring\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>professor</th>\n",
       "      <th>course</th>\n",
       "      <th>year</th>\n",
       "      <th>season</th>\n",
       "      <th>average_gpa</th>\n",
       "      <th>num_students</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A Anthony</td>\n",
       "      <td>AMST202</td>\n",
       "      <td>2016</td>\n",
       "      <td>fall</td>\n",
       "      <td>2.462500</td>\n",
       "      <td>24.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A Anthony</td>\n",
       "      <td>AMST202</td>\n",
       "      <td>2017</td>\n",
       "      <td>spring</td>\n",
       "      <td>2.934783</td>\n",
       "      <td>23.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A Anthony</td>\n",
       "      <td>AMST203</td>\n",
       "      <td>2017</td>\n",
       "      <td>fall</td>\n",
       "      <td>2.796429</td>\n",
       "      <td>28.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A Anthony</td>\n",
       "      <td>AMST203</td>\n",
       "      <td>2018</td>\n",
       "      <td>fall</td>\n",
       "      <td>3.204651</td>\n",
       "      <td>43.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A Anthony</td>\n",
       "      <td>AMST203</td>\n",
       "      <td>2018</td>\n",
       "      <td>spring</td>\n",
       "      <td>2.476190</td>\n",
       "      <td>21.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   professor   course  year  season  average_gpa  num_students\n",
       "0  A Anthony  AMST202  2016    fall     2.462500          24.0\n",
       "1  A Anthony  AMST202  2017  spring     2.934783          23.0\n",
       "2  A Anthony  AMST203  2017    fall     2.796429          28.0\n",
       "3  A Anthony  AMST203  2018    fall     3.204651          43.0\n",
       "4  A Anthony  AMST203  2018  spring     2.476190          21.0"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sort by the following to ensure that grades corresponding to the same semester get grouped together\n",
    "grades_df = grades_df.sort_values(by = [\"professor\", \"course\", \"year\", \"season\"], ignore_index = True)\n",
    "\n",
    "average_grades_df = pd.DataFrame()\n",
    "# GPA values for each letter grade\n",
    "gpa = {\"A+\":4.0, \"A\":4.0, \"A-\":3.7,\"B+\":3.3, \"B\":3.0, \"B-\":2.7, \"C+\":2.3, \"C\":2.0, \"C-\":1.7, \"D+\":1.3, \"D\":1.0, \"D-\":0.7, \"F\":0.0}\n",
    "\n",
    "values_to_check = [\"professor\", \"course\", \"year\", \"season\"]\n",
    "curr = [grades_df.at[0, \"professor\"], grades_df.at[0, \"course\"], grades_df.at[0, \"year\"], grades_df.at[0, \"season\"]]\n",
    "count = 0\n",
    "averages = [0, 0]\n",
    "for index, row in grades_df.iterrows():\n",
    "    match = True\n",
    "    # see if the next row in the dataframe is for the current semester\n",
    "    for i in range(4):\n",
    "        if curr[i] != grades_df.at[index, values_to_check[i]]:\n",
    "            match = False\n",
    "    if not match:\n",
    "        # once it is not a match, write the current accumulated information to the dataframe and reset\n",
    "        for i in range(4):\n",
    "            if averages[1] != 0:\n",
    "                average_grades_df.at[count, values_to_check[i]] = curr[i]\n",
    "            curr[i] = grades_df.at[index, values_to_check[i]]\n",
    "        # it is possible for the number of students taking a class to be 0, this would occur when all of the students\n",
    "        # in a class have grades corresponding to W or Other, neither of which have a GPA value\n",
    "        if averages[1] != 0:\n",
    "            average_grades_df.at[count, \"average_gpa\"] = averages[0]/averages[1]\n",
    "            average_grades_df.at[count, \"num_students\"] = averages[1]\n",
    "            count = count + 1\n",
    "        averages = [0, 0]\n",
    "    for i in gpa.keys():\n",
    "        averages[0] = averages[0] + gpa.get(i)*grades_df.at[index, i]\n",
    "        averages[1] = averages[1] + grades_df.at[index, i]\n",
    "# add in the last row\n",
    "for i in range(4):\n",
    "    if averages[1] != 0:\n",
    "        average_grades_df.at[count, values_to_check[i]] = curr[i]\n",
    "if averages[1] != 0:\n",
    "    average_grades_df.at[count, \"average_gpa\"] = averages[0]/averages[1]\n",
    "    average_grades_df.at[count, \"num_students\"] = averages[1]\n",
    "\n",
    "\n",
    "average_grades_df.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we can join these two dataframes together, before combining them so that each professor corresponds to one row in the dataframe, storing all of their review and grade information in arrays that can be exploded out in the future. The reason for doing this is in order to more easily match with the data from the Diamondback. Further down the line, we will then reseparate our data out to perform the necessary analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>course</th>\n",
       "      <th>year</th>\n",
       "      <th>season</th>\n",
       "      <th>average_rating</th>\n",
       "      <th>num_reviews</th>\n",
       "      <th>average_gpa</th>\n",
       "      <th>num_students</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A Anthony</td>\n",
       "      <td>AMST203</td>\n",
       "      <td>2018</td>\n",
       "      <td>summer</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A Kruglanski</td>\n",
       "      <td>PSYC489H</td>\n",
       "      <td>2015</td>\n",
       "      <td>fall</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A Sharma</td>\n",
       "      <td>ASTR300</td>\n",
       "      <td>2019</td>\n",
       "      <td>fall</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A Sharma</td>\n",
       "      <td>ASTR300</td>\n",
       "      <td>2019</td>\n",
       "      <td>spring</td>\n",
       "      <td>1.5</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.850877</td>\n",
       "      <td>57.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A Sharma</td>\n",
       "      <td>ASTR300</td>\n",
       "      <td>2020</td>\n",
       "      <td>fall</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           name    course  year  season  average_rating  num_reviews  \\\n",
       "0     A Anthony   AMST203  2018  summer             1.0          1.0   \n",
       "1  A Kruglanski  PSYC489H  2015    fall             2.0          1.0   \n",
       "2      A Sharma   ASTR300  2019    fall             1.0          1.0   \n",
       "3      A Sharma   ASTR300  2019  spring             1.5          2.0   \n",
       "4      A Sharma   ASTR300  2020    fall             2.0          1.0   \n",
       "\n",
       "   average_gpa  num_students  \n",
       "0          NaN           NaN  \n",
       "1          NaN           NaN  \n",
       "2          NaN           NaN  \n",
       "3     2.850877          57.0  \n",
       "4          NaN           NaN  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "average_grades_df = average_grades_df.rename(columns = {\"professor\" : \"name\"})\n",
    "\n",
    "both_averages_df = pd.merge(\n",
    "    average_reviews_df,\n",
    "    average_grades_df,\n",
    "    how = \"outer\",\n",
    "    on = [\"name\", \"course\", \"year\", \"season\"]\n",
    ")\n",
    "\n",
    "both_averages_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>course</th>\n",
       "      <th>semester</th>\n",
       "      <th>average_rating</th>\n",
       "      <th>num_reviews</th>\n",
       "      <th>average_gpa</th>\n",
       "      <th>num_students</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A ANTHONY</td>\n",
       "      <td>[AMST203, AMST202, AMST202, AMST203, AMST203, ...</td>\n",
       "      <td>[summer 2018, fall 2016, spring 2017, fall 201...</td>\n",
       "      <td>[1.0, nan, nan, nan, nan, nan]</td>\n",
       "      <td>[1.0, nan, nan, nan, nan, nan]</td>\n",
       "      <td>[nan, 2.46, 2.93, 2.8, 3.2, 2.48]</td>\n",
       "      <td>[0, 24, 23, 28, 43, 21]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A KRUGLANSKI</td>\n",
       "      <td>[PSYC489H, PSYC489H, PSYC489H, PSYC489T, PSYC4...</td>\n",
       "      <td>[fall 2015, spring 2014, spring 2015, spring 2...</td>\n",
       "      <td>[2.0, nan, nan, nan, nan, nan, nan, nan, nan, ...</td>\n",
       "      <td>[1.0, nan, nan, nan, nan, nan, nan, nan, nan, ...</td>\n",
       "      <td>[nan, 3.51, 3.55, 3.89, 3.46, 3.56, 3.52, 3.45...</td>\n",
       "      <td>[0, 16, 8, 17, 20, 14, 19, 24, 10, 19, 3, 10, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A SHARMA</td>\n",
       "      <td>[ASTR300, ASTR300, ASTR300, ASTR300, ASTR300, ...</td>\n",
       "      <td>[fall 2019, spring 2019, fall 2020, winter 202...</td>\n",
       "      <td>[1.0, 1.5, 2.0, 3.0, nan, nan, nan, nan]</td>\n",
       "      <td>[1.0, 2.0, 1.0, 1.0, nan, nan, nan, nan]</td>\n",
       "      <td>[nan, 2.85, nan, nan, 2.92, 2.98, 2.69, 3.28]</td>\n",
       "      <td>[0, 57, 0, 0, 51, 59, 47, 58]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A.U. SHANKAR</td>\n",
       "      <td>[CMSC216, CMSC216, CMSC216, CMSC216, CMSC216, ...</td>\n",
       "      <td>[fall 2017, spring 2018, winter 2018, fall 201...</td>\n",
       "      <td>[1.0, 2.0, 1.0, 1.0, 3.0, 2.0, 2.2, 2.66666666...</td>\n",
       "      <td>[1.0, 1.0, 1.0, 2.0, 4.0, 2.0, 5.0, 3.0, 2.0, ...</td>\n",
       "      <td>[2.62, nan, nan, 1.99, 2.23, 2.7, 2.32, nan, 3...</td>\n",
       "      <td>[120, 0, 0, 114, 125, 55, 102, 0, 33, 39, 0, 3...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AARON BARTLETT</td>\n",
       "      <td>[ENGL101, ENGL265, ENGL265, ENGL101, ENGL243]</td>\n",
       "      <td>[fall 2020, fall 2022, spring 2023, fall 2019,...</td>\n",
       "      <td>[1.0, 1.0, 4.0, nan, nan]</td>\n",
       "      <td>[1.0, 2.0, 1.0, nan, nan]</td>\n",
       "      <td>[nan, 3.3, nan, 2.66, 3.37]</td>\n",
       "      <td>[0, 29, 0, 19, 18]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             name                                             course  \\\n",
       "0       A ANTHONY  [AMST203, AMST202, AMST202, AMST203, AMST203, ...   \n",
       "1    A KRUGLANSKI  [PSYC489H, PSYC489H, PSYC489H, PSYC489T, PSYC4...   \n",
       "2        A SHARMA  [ASTR300, ASTR300, ASTR300, ASTR300, ASTR300, ...   \n",
       "3    A.U. SHANKAR  [CMSC216, CMSC216, CMSC216, CMSC216, CMSC216, ...   \n",
       "4  AARON BARTLETT      [ENGL101, ENGL265, ENGL265, ENGL101, ENGL243]   \n",
       "\n",
       "                                            semester  \\\n",
       "0  [summer 2018, fall 2016, spring 2017, fall 201...   \n",
       "1  [fall 2015, spring 2014, spring 2015, spring 2...   \n",
       "2  [fall 2019, spring 2019, fall 2020, winter 202...   \n",
       "3  [fall 2017, spring 2018, winter 2018, fall 201...   \n",
       "4  [fall 2020, fall 2022, spring 2023, fall 2019,...   \n",
       "\n",
       "                                      average_rating  \\\n",
       "0                     [1.0, nan, nan, nan, nan, nan]   \n",
       "1  [2.0, nan, nan, nan, nan, nan, nan, nan, nan, ...   \n",
       "2           [1.0, 1.5, 2.0, 3.0, nan, nan, nan, nan]   \n",
       "3  [1.0, 2.0, 1.0, 1.0, 3.0, 2.0, 2.2, 2.66666666...   \n",
       "4                          [1.0, 1.0, 4.0, nan, nan]   \n",
       "\n",
       "                                         num_reviews  \\\n",
       "0                     [1.0, nan, nan, nan, nan, nan]   \n",
       "1  [1.0, nan, nan, nan, nan, nan, nan, nan, nan, ...   \n",
       "2           [1.0, 2.0, 1.0, 1.0, nan, nan, nan, nan]   \n",
       "3  [1.0, 1.0, 1.0, 2.0, 4.0, 2.0, 5.0, 3.0, 2.0, ...   \n",
       "4                          [1.0, 2.0, 1.0, nan, nan]   \n",
       "\n",
       "                                         average_gpa  \\\n",
       "0                  [nan, 2.46, 2.93, 2.8, 3.2, 2.48]   \n",
       "1  [nan, 3.51, 3.55, 3.89, 3.46, 3.56, 3.52, 3.45...   \n",
       "2      [nan, 2.85, nan, nan, 2.92, 2.98, 2.69, 3.28]   \n",
       "3  [2.62, nan, nan, 1.99, 2.23, 2.7, 2.32, nan, 3...   \n",
       "4                        [nan, 3.3, nan, 2.66, 3.37]   \n",
       "\n",
       "                                        num_students  \n",
       "0                            [0, 24, 23, 28, 43, 21]  \n",
       "1  [0, 16, 8, 17, 20, 14, 19, 24, 10, 19, 3, 10, ...  \n",
       "2                      [0, 57, 0, 0, 51, 59, 47, 58]  \n",
       "3  [120, 0, 0, 114, 125, 55, 102, 0, 33, 39, 0, 3...  \n",
       "4                                 [0, 29, 0, 19, 18]  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def combine(group):\n",
    "     return pd.Series({\n",
    "        'course': group['course'].tolist(),\n",
    "        'semester': [a + \" \" + b for a, b in zip(group['season'], group['year'])],\n",
    "        'average_rating': group['average_rating'].tolist(),\n",
    "        'num_reviews': group['num_reviews'].tolist(),\n",
    "        'average_gpa': [round(x, 2) for x in group['average_gpa']],\n",
    "        'num_students': [int(x) for x in np.nan_to_num(group['num_students'])]\n",
    "    })\n",
    "df_grouped = both_averages_df.groupby(['name']).apply(combine).reset_index()\n",
    "df_grouped[\"name\"] = df_grouped[\"name\"].apply(lambda x: x.split()[0].upper()) + \" \" +df_grouped[\"name\"].apply(lambda x: x.split()[-1].upper())\n",
    "\n",
    "if os.path.exists(\"src/1_collect_data/planet_terp_data/PT_grade_data.csv\") == False:\n",
    "    df_grouped.to_csv(f'src/1_collect_data/planet_terp_data/PT_combined_data.csv', index=False)\n",
    "\n",
    "df_grouped.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Cleaning <a class=\"anchor\" id = \"data-cleaning\"></a>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have all of the data that we will be working with, the next stage of the Data Science Lifecycle is Data Cleaning. During this stage, we will go through all of our data and try to eliminate any errors that we can find, ensuring that the data that we use in our analyses will be as ideal as possible."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Duplicates in Diamondback <a class=\"anchor\" id = \"duplicates-in-diamondback\"></a>\n",
    "\n",
    "One of the issues in our current database of salary data is that the same person could be in there listed under multiple names. For example, David Todd is listed as *Todd, David Y*, but also as *Todd, David Y.* and *Todd, David Yandell*. This would prove an issue if left unchecked, as David Todd would not get properly matched with his PlanetTerp reviews and grade distributions. As such, we need to be able to merge these three people to be classified under the same person. \n",
    "\n",
    "The first requirement for someone to be considered the same person is that their name must match. To account for multiple middle names, middle initials, and other potential name setups, we look only at the first word after the comma and the last word before the comma, defining those as a person's first and last name, respectively. As you can see in our previous example, this yields David Todd for all three entries. Additionally, we check that their is no overlap in the years they've taught. In our example, *Todd, David Y* has only taught in 2015 and 2016. *Todd, David Y.* then taught from 2017 to 2020, and *Todd, David Yandell* taught in 2021 and 2022. If there is an overlap, we can say that these entries correspond to different people. No overlap ensures the possibility that this is the same person.\n",
    "\n",
    "The final requirement that we check is if there is at least some overlap in the department that they were listed under. In our example, all three of the David Todds were listed under the Arts and Humanities department. Since these three entries meet all three of the requirements that we have laid out, we can say that it is very likely that this is in fact the same person, simply changing what their name is listed as officially. If any entry fails one of the three requirements listed above, we can say that they are different people. If they meet all three, we cannot guarantee that they are the same person, as it is still possible that two people with the same name are in the same department with no overlap in years, but the odds of that are small enough that we can say that any entries that meet all three requirements are likely the same person."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>years_taught</th>\n",
       "      <th>salaries</th>\n",
       "      <th>departments</th>\n",
       "      <th>real_name(s)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>EAMAN KARIM</td>\n",
       "      <td>[2018, 2019]</td>\n",
       "      <td>[48000.0, 48960.0]</td>\n",
       "      <td>['ENGR', 'ENGR']</td>\n",
       "      <td>A Karim, Eaman</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>MICHAEL A'HEARN</td>\n",
       "      <td>[2013, 2014, 2015, 2016, 2017]</td>\n",
       "      <td>[125817.0, 130849.69, 145530.01, 155925.01, 13...</td>\n",
       "      <td>['CMNS', 'CMNS', 'CMNS', 'CMNS', 'CMNS']</td>\n",
       "      <td>A'Hearn, Michael F.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>MOHAMMED AMIN</td>\n",
       "      <td>[2015]</td>\n",
       "      <td>[46500.0]</td>\n",
       "      <td>['CMNS']</td>\n",
       "      <td>AMIN, MOHAMMED NURUL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>WILLIAM AARHUS</td>\n",
       "      <td>[2016, 2017, 2018, 2019, 2020, 2021, 2022]</td>\n",
       "      <td>[75000.0, 75750.0, 75750.0, 77265.0, 80780.68,...</td>\n",
       "      <td>['SVPA', 'SVPA', 'SVPA', 'SVPA', 'SVPA', 'EXST...</td>\n",
       "      <td>Aarhus, William H</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>BERHANE ABADI</td>\n",
       "      <td>[2022]</td>\n",
       "      <td>[31278.0]</td>\n",
       "      <td>['VPSA']</td>\n",
       "      <td>Abadi, Berhane</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              name                                years_taught  \\\n",
       "1      EAMAN KARIM                                [2018, 2019]   \n",
       "2  MICHAEL A'HEARN              [2013, 2014, 2015, 2016, 2017]   \n",
       "3    MOHAMMED AMIN                                      [2015]   \n",
       "4   WILLIAM AARHUS  [2016, 2017, 2018, 2019, 2020, 2021, 2022]   \n",
       "5    BERHANE ABADI                                      [2022]   \n",
       "\n",
       "                                            salaries  \\\n",
       "1                                 [48000.0, 48960.0]   \n",
       "2  [125817.0, 130849.69, 145530.01, 155925.01, 13...   \n",
       "3                                          [46500.0]   \n",
       "4  [75000.0, 75750.0, 75750.0, 77265.0, 80780.68,...   \n",
       "5                                          [31278.0]   \n",
       "\n",
       "                                         departments          real_name(s)  \n",
       "1                                   ['ENGR', 'ENGR']        A Karim, Eaman  \n",
       "2           ['CMNS', 'CMNS', 'CMNS', 'CMNS', 'CMNS']   A'Hearn, Michael F.  \n",
       "3                                           ['CMNS']  AMIN, MOHAMMED NURUL  \n",
       "4  ['SVPA', 'SVPA', 'SVPA', 'SVPA', 'SVPA', 'EXST...     Aarhus, William H  \n",
       "5                                           ['VPSA']        Abadi, Berhane  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"src/1_collect_data/salary_data/DB_combined_data.csv\")\n",
    "\n",
    "combine_df = pd.DataFrame()\n",
    "\n",
    "curr = [\"\", \"\", \"\", \"\"]\n",
    "names = []\n",
    "count = 0\n",
    "\n",
    "# method to find the intersection of two lists\n",
    "def intersection(l1, l2):\n",
    "    output = []\n",
    "    temp1 = l1[1:-1]\n",
    "    temp2 = l2[1:-1]\n",
    "    list1 = list(temp1.split(\", \"))\n",
    "    list2 = list(temp2.split(\", \"))\n",
    "    for i in list1:\n",
    "        if i in list2:\n",
    "            output.append(i)\n",
    "    return output\n",
    "\n",
    "\n",
    "for index, row in df.iterrows():\n",
    "    # check the three conditions\n",
    "    if (curr[0] == df.at[index, \"name\"] and \n",
    "        intersection(curr[1], df.at[index, \"years_taught\"]) == [] and \n",
    "        intersection(curr[3], df.at[index, \"departments\"]) != []):\n",
    "\n",
    "        # combining professors that are detected to be the same\n",
    "        curr[1] = curr[1][:-1] + \", \" + (df.at[index, \"years_taught\"])[1:]\n",
    "        curr[2] = curr[2][:-1] + \", \" + (df.at[index, \"salaries\"])[1:]\n",
    "        curr[3] = curr[3][:-1] + \", \" +  (df.at[index, \"departments\"])[1:]\n",
    "        names.append(df.at[index, \"Employee\"])\n",
    "\n",
    "        # if we end on a match, add that match to the dataframe\n",
    "        if index == len(df.index) -1:\n",
    "            combine_df.at[count, \"name\"] = curr[0]\n",
    "            combine_df.at[count, \"years_taught\"] = curr[1]\n",
    "            combine_df.at[count, \"salaries\"] = curr[2]\n",
    "            combine_df.at[count, \"departments\"] = curr[3]\n",
    "            combine_df.at[count, \"real_name(s)\"] = \" | \".join(names)\n",
    "            names = [df.at[index, \"Employee\"]]\n",
    "            curr = [df.at[index, \"name\"], df.at[index, \"years_taught\"], df.at[index, \"salaries\"], df.at[index, \"departments\"]]\n",
    "            count = count + 1\n",
    "    \n",
    "    # once we detect someone isn't a match, add the accumulated information to the dataframe\n",
    "    else:\n",
    "        combine_df.at[count, \"name\"] = curr[0]\n",
    "        combine_df.at[count, \"years_taught\"] = curr[1]\n",
    "        combine_df.at[count, \"salaries\"] = curr[2]\n",
    "        combine_df.at[count, \"departments\"] = curr[3]\n",
    "        combine_df.at[count, \"real_name(s)\"] = \" | \".join(names)\n",
    "        names = [df.at[index, \"Employee\"]]\n",
    "        curr = [df.at[index, \"name\"], df.at[index, \"years_taught\"], df.at[index, \"salaries\"], df.at[index, \"departments\"]]\n",
    "        count = count + 1\n",
    "\n",
    "combine_df = combine_df.drop(labels = 0, axis = 0)\n",
    "\n",
    "combine_df.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Going back to our favorite English professor David Todd, we can see that all of his information has now been combined together, with all of his various aliases listed under the \"real_name(s)\" column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>years_taught</th>\n",
       "      <th>salaries</th>\n",
       "      <th>departments</th>\n",
       "      <th>real_name(s)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>22125</th>\n",
       "      <td>DAVID TODD</td>\n",
       "      <td>[2015, 2016, 2017, 2018, 2019, 2020, 2021, 2022]</td>\n",
       "      <td>[8949.58, 29107.38, 30000.0, 33000.0, 33660.0,...</td>\n",
       "      <td>['ARHU', 'ARHU', 'ARHU', 'ARHU', 'ARHU', 'ARHU...</td>\n",
       "      <td>Todd, David Y | Todd, David Y. | Todd, David Y...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             name                                      years_taught  \\\n",
       "22125  DAVID TODD  [2015, 2016, 2017, 2018, 2019, 2020, 2021, 2022]   \n",
       "\n",
       "                                                salaries  \\\n",
       "22125  [8949.58, 29107.38, 30000.0, 33000.0, 33660.0,...   \n",
       "\n",
       "                                             departments  \\\n",
       "22125  ['ARHU', 'ARHU', 'ARHU', 'ARHU', 'ARHU', 'ARHU...   \n",
       "\n",
       "                                            real_name(s)  \n",
       "22125  Todd, David Y | Todd, David Y. | Todd, David Y...  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "david_todd = combine_df.loc[[combine_df.index[combine_df['name'] == \"DAVID TODD\"].tolist()[0]]]\n",
    "david_todd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.exists(\"src/2_clean_data/clean_salary_data.csv\") == False:\n",
    "    combine_df.to_csv(f'src/2_clean_data/clean_salary_data.csv', index=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Matching Names <a class=\"anchor\" id = \"matching-names\"></a>\n",
    "\n",
    "Now that we have formatted all of our data, the next part we would like to do is join the data from our two sources together. We have already reformatted all of the names from the Diamondback to follow the format used at PlanetTerp. We went from the Diamondback's format of last name, followed by a comma, and finally first name, with potentially a middle name or initial, to PlanetTerp's format of first name followed by last name. From here, we can then join our data on a professor's name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LEFT ONLY: 655\n",
      "BOTH: 2490\n"
     ]
    }
   ],
   "source": [
    "gpa_review_df = pd.read_csv('src/1_collect_data/planet_terp_data/PT_combined_data.csv')\n",
    "salary_df = pd.read_csv(\"src/2_clean_data/clean_salary_data.csv\")\n",
    "\n",
    "outer = pd.merge(\n",
    "    gpa_review_df,\n",
    "    salary_df,\n",
    "    how = \"outer\",\n",
    "    on = \"name\",\n",
    "    indicator=True\n",
    ")\n",
    "\n",
    "left_only = outer[outer['_merge'] == 'left_only']\n",
    "print(\"LEFT ONLY: \" + str(len(left_only)))\n",
    "both = outer[outer['_merge'] == 'both']\n",
    "print(\"BOTH: \" + str(len(both)))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Left only corresponds to all of the people that were found only in PlanetTerp and not in the Diamondback, whereas both corresponds to an inner join. From here, we now look for any potential duplicates in our inner join."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "54\n"
     ]
    }
   ],
   "source": [
    "curr_prof = \"\"\n",
    "dups = []\n",
    "for index, row in both.iterrows():\n",
    "    if both.at[index, \"name\"] == curr_prof:\n",
    "        dups.append(both.at[index, \"name\"])\n",
    "    else:\n",
    "        curr_prof = both.at[index, \"name\"]\n",
    "\n",
    "print(len(dups))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From here, we now have to manually look through all of our duplicates. Most of the duplicates found were people that just happened to have the same name but were certainly different people, either belonging to different departments, working at the same time, or both. In this case, we would have to cross refrence to see who is actually the one with the correct salary data, and remove the other from the database. There were a few cases in which someone was listed twice as the same person, but our previous method missed it. In this case, we used the following method to manually combine these two entries. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_dups(i1, i2, both):\n",
    "    for i in i2:\n",
    "        both.at[i1, \"years_taught\"] = both.at[i1, \"years_taught\"][:-1] + \", \" + both.at[i, \"years_taught\"][1:]\n",
    "        both.at[i1, \"departments\"] = both.at[i1, \"departments\"][:-1] + \", \" + both.at[i, \"departments\"][1:]\n",
    "        both.at[i1, \"salaries\"] = both.at[i1, \"salaries\"][:-1] + \", \" + both.at[i, \"salaries\"][1:]\n",
    "        both.at[i1, \"real_name(s)\"] = both.at[i1, \"real_name(s)\"] + \" | \" + both.at[i, \"real_name(s)\"]\n",
    "    return both"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, there were a few cases in which the information listed in PlanetTerp was wrong. For example, [Daniel Foster](https://planetterp.com/professor/foster_daniel) is listed as a professor teaching both Communicates and various Music classes on PlanetTerp. However, there are two Daniel Fosters in our salary data, being Daniel L Foster and Daniel H Foster. A quick [directory search](https://identity.umd.edu/search) for \"Daniel Foster\" confirms this, there are in fact two different Daniel Fosters working at UMD."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"daniel_foster.png\" alt=\"Directory Search for Daniel Foster\" />"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Two Daniel Fosters, one teaching Communication and one teaching Music. However, it appears that they are being listed as the same person in PlanetTerp. It is likely because they saw two people named Daniel Foster, both teaching in the Arts and Humanities Department, and simply assumed they were the same person. As such, we manually corrected this, separating the two into their own entries and giving each the data for their resepective classes. Most of the code used in this section is manually reading the dataframe, removing specific indicies and separating things out ourselves, and is not displayed here. To see the full code used in this section, please visit our github [here](https://github.com/achen132/achen132.github.io/blob/main/src/2_clean_data/join.ipynb)."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting Departments <a class=\"anchor\" id = \"getting-departments\"></a>\n",
    "\n",
    "Going back to our previous joins, we can see that there were 2490 professors who appeared in both PlanetTerp and the Diamondback databases and 655 who only appeared in PlanetTerp. As such, for each of these 655 people, we then went through all of the professors listed in the Diamondback database to try and see if we could find someone who did not get properly matched. To do this, we flagged a potential candidate in the Diamondback data as someone whose name contained the first and last name listed in PlanetTerp and was listed under a department that included the classes that they taught on PlanetTerp. To perform this task, we first needed to get a comprehensive list of every subject and what department they would be listed under."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['PSYC' 'ASTR' 'CMSC' 'ECON' 'HESI' 'EDHI' 'COMM' 'INST' 'ENAE' 'ENME'\n",
      " 'ENMA' 'ENRE' 'ARTH' 'PHYS' 'STAT' 'ENGL' 'PHSC' 'ANTH' 'BIOE' 'GEMS'\n",
      " 'MATH' 'BMGT' 'BULM' 'CMLT' 'GERM' 'JWST' 'ISRL' 'BUSO' 'DANC' 'ARHU'\n",
      " 'TDPS' 'UNIV' 'ENEE' 'PERS' 'ARAB' 'ENCE' 'HIST' 'HACS' 'CCJS' 'GEOL'\n",
      " 'FIRE' 'SOCY' 'CPSD' 'CPSP' 'PLCY' 'AASP' 'HNUH' 'WMST' 'BUFN' 'BUSI'\n",
      " 'ENTS' 'MSML' 'HONR' 'PUAF' 'JOUR' 'PHIL' 'LING' 'BSCI' 'BIOL' 'AOSC'\n",
      " 'HDCC' 'LGBT' 'EDHD' 'EDUC' 'TLTC' 'EDMS' 'CHEM' 'CPMS' 'ENES' 'HESP'\n",
      " 'HEBR' 'GEOG' 'LARC' 'EDCP' 'IDEA' 'FMSC' 'NEUR' 'MIEH' 'BUMK' 'ENST'\n",
      " 'ANSC' 'INAG' 'CHBE' 'ENCH' 'SPAN' 'PORT' 'USLT' 'SLLC' 'ENTM' 'BUSM'\n",
      " 'FREN' 'AMST' 'KNES' 'MLSC' 'THET' 'CHIN' 'EALL' 'BUMO' 'EDCI' 'TLPL'\n",
      " 'ENPM' 'AREC' 'BISI' 'CBMG' 'ENSP' 'GVPT' 'PHPE' 'ENNU' 'HLSA' 'HLTH'\n",
      " 'BSOS' 'SPHL' 'BUDT' 'CHSE' 'HHUM' 'CPSF' 'LBSC' 'AAST' 'BCHM' 'EPIB'\n",
      " 'ARTT' 'BUAC' 'HLSC' 'CLFS' 'SMLP' 'HLMN' 'MLAW' 'SURV' 'AGNR' 'PLSC'\n",
      " 'EDPS' 'EDSP' 'ENFP' 'INFM' 'UMEI' 'BEES' 'AMSC' 'EMBA' 'CLAS' 'LATN'\n",
      " 'IMMR' 'BIOM' 'URSP' 'CHPH' 'CPBE' 'NACS' 'MUSC' 'MUED' 'IMDM' 'CINE'\n",
      " 'FILM' 'NFSC' 'ENSE' 'CPSS' 'AGST' 'DATA' 'RUSS' 'ARCH' 'CPGH' 'RELS'\n",
      " 'BSST' 'WGSS' 'CPJT' 'JAPN' 'ITAL' 'MUET' 'LACS' 'GREK' 'LASC' 'BSGC'\n",
      " 'CPSA' 'RDEV' 'BSCV' 'CPSN' 'HGLO' 'HEIP' 'BIPH' 'PEER' 'ENEB' 'BMSO'\n",
      " 'CPSG' 'HBUS' 'CONS' 'CPPL' 'ENBC' 'SLAA' 'CPET' 'VMSC' 'KORA' 'MEES']\n",
      "190\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('src/2_clean_data/combined_data.csv')\n",
    "\n",
    "#Columns with lists are represented as strings, so this is converting them into list/np.array types\n",
    "\n",
    "for index, row in df.iterrows():\n",
    "    df.iloc[index]['salaries'] = ast.literal_eval(df.iloc[index]['salaries'])\n",
    "    df.iloc[index]['semester'] = ast.literal_eval(df.iloc[index]['semester'])\n",
    "    df.iloc[index]['years_taught'] = ast.literal_eval(df.iloc[index]['years_taught'])\n",
    "    df.iloc[index]['course'] = ast.literal_eval(df.iloc[index]['course'])\n",
    "    df.iloc[index]['average_rating'] = np.fromstring(df.iloc[index]['average_rating'].strip(\"[]\"), sep=',')\n",
    "    df.iloc[index]['num_reviews'] = np.fromstring(df.iloc[index]['num_reviews'].strip(\"[]\"), sep=',')\n",
    "    df.iloc[index]['average_gpa'] = np.fromstring(df.iloc[index]['average_gpa'].strip(\"[]\"), sep=',')\n",
    "    df.iloc[index]['num_students'] = ast.literal_eval(df.iloc[index]['num_students'])\n",
    "\n",
    "df = df.explode(['course'])\n",
    "\n",
    "uniqueCourses = df['course'].str[0:4].unique()\n",
    "\n",
    "print(df['course'].str[0:4].unique())\n",
    "print(len(df['course'].str[0:4].unique()))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From here, we need to start matching classes to what department they are listed under. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get full names for each department\n",
    "\n",
    "code_fullname_dict = {}\n",
    "\n",
    "undergrad_majors = requests.get(\"https://academiccatalog.umd.edu/undergraduate/approved-courses/\")\n",
    "undergrad_majors_soup = BeautifulSoup(undergrad_majors.text, 'html.parser')\n",
    "\n",
    "for major in undergrad_majors_soup.find(id=\"/undergraduate/approved-courses/\").find_all(\"li\"):\n",
    "    majorInfo = major.text.replace('\\u200b', '').split(' - ')\n",
    "    code_fullname_dict[majorInfo[0]] = majorInfo[1].strip()\n",
    "    \n",
    "grad_majors = requests.get(\"https://academiccatalog.umd.edu/graduate/courses/\")\n",
    "grad_majors_soup = BeautifulSoup(grad_majors.text, 'html.parser')\n",
    "\n",
    "for major in grad_majors_soup.find(id=\"/graduate/courses/\").find_all(\"li\"):\n",
    "    majorInfo = major.text.replace('\\u200b', '').split(' - ')\n",
    "    if majorInfo[0] not in code_fullname_dict:\n",
    "        code_fullname_dict[majorInfo[0]] = majorInfo[1].strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BUSO\n",
      "BMSO\n",
      "HBUS\n"
     ]
    }
   ],
   "source": [
    "#Manually add full names for codes that don't have full names yet\n",
    "\n",
    "for code in uniqueCourses:\n",
    "    if code not in code_fullname_dict:\n",
    "        print(code)\n",
    "\n",
    "code_fullname_dict['BUSO'] = 'Online MBA Program'\n",
    "code_fullname_dict['BMSO'] = 'Online MS in Business Analytics'\n",
    "code_fullname_dict['HBUS'] = \"Interdisciplinary Business Honors\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get colleges for some grad school majors\n",
    "\n",
    "final_code_to_school = {}\n",
    "\n",
    "gradMajorsSchools = requests.get(\"https://gradschool.umd.edu/admissions/programs-a-to-z\")\n",
    "gradMajorsSchools_soup = BeautifulSoup(gradMajorsSchools.text, 'html.parser')\n",
    "\n",
    "for row in gradMajorsSchools_soup.find_all(\"table\")[1].find_all(\"tr\"):\n",
    "    if len(row.find_all(\"strong\")) == 0:\n",
    "        final_code_to_school[row.find_all(\"td\")[1].text] = row.find_all(\"td\")[2].text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get majors under each school\n",
    "\n",
    "majors_schools = {}\n",
    "\n",
    "schools = requests.get(\"https://academiccatalog.umd.edu/undergraduate/colleges-schools/\")\n",
    "schools_soup =  BeautifulSoup(schools.text, 'html.parser')\n",
    "\n",
    "links_to_schools = {}\n",
    "\n",
    "for schools in schools_soup.find_all(id=\"/undergraduate/colleges-schools/\"):\n",
    "    for majors in schools.find_all(\"li\"):\n",
    "        if majors.find(\"a\").get(\"href\").count(\"/\") == 4:\n",
    "            links_to_schools[majors.find(\"a\").text] = majors.find(\"a\").get(\"href\")\n",
    "\n",
    "\n",
    "for school in links_to_schools:\n",
    "    majors = requests.get(\"https://academiccatalog.umd.edu\" + links_to_schools[school] + \"#degreeprogramstext\")\n",
    "    majors_soup = BeautifulSoup(majors.text, 'html.parser')\n",
    "\n",
    "    if (len(majors_soup.find_all(id='degreeprogramstextcontainer')) == 0): #Journalism school and office of undergraduate studies\n",
    "        for section in majors_soup.find_all(id='programstextcontainer'):\n",
    "            for program in section.find_all(\"ul\")[0]:\n",
    "                majors_schools[program.text] = school\n",
    "    else:\n",
    "        for section in majors_soup.find_all(id='degreeprogramstextcontainer'):\n",
    "            for program in section.find_all(\"li\"):\n",
    "                majors_schools[program.text] = school"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Rename long college names to short version\n",
    "\n",
    "def rename_colleges(dictionary):\n",
    "    for code in dictionary.keys():\n",
    "        if 'business' in dictionary[code].lower():\n",
    "            dictionary[code] = 'BMGT' #'Robert H. Smith School of Business'\n",
    "        elif 'engineering' in dictionary[code].lower():\n",
    "            dictionary[code] = 'ENGR' #'A. James Clark School of Engineering'\n",
    "        elif 'information studies' in dictionary[code].lower():\n",
    "            dictionary[code] = 'INFO' #'College of Information Studies'\n",
    "        elif 'computer' in dictionary[code].lower():\n",
    "            dictionary[code] = 'CMNS' #'College of Computer, Mathematical, and Natural Sciences'\n",
    "        elif 'arts' in dictionary[code].lower():\n",
    "            dictionary[code] = 'ARHU'\n",
    "        elif 'behavioral' in dictionary[code].lower():\n",
    "            dictionary[code] = 'BSOS'\n",
    "        elif 'education' in dictionary[code].lower():\n",
    "            dictionary[code] = 'EDUC'\n",
    "        elif 'architecture' in dictionary[code].lower():\n",
    "            dictionary[code] = 'ARCH'\n",
    "        elif 'health' in dictionary[code].lower():\n",
    "            dictionary[code] = 'SPHL'\n",
    "        elif 'agric' in dictionary[code].lower():\n",
    "            dictionary[code] = 'AGNR'\n",
    "        elif 'journalism' in dictionary[code].lower():\n",
    "            dictionary[code] = 'JOUR'\n",
    "        elif 'inter' in dictionary[code].lower():\n",
    "            dictionary[code] = 'Office of Undergraduate Studies'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "rename_colleges(final_code_to_school)\n",
    "rename_colleges(majors_schools)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_matching_string(string, string_list):\n",
    "    matches = []\n",
    "    for element in string_list:\n",
    "        if string.lower() in element.lower():\n",
    "            matches.append(element)\n",
    "    return matches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "#biolog - CMNS\n",
    "#engineer - A James Clark\n",
    "#ed - College of Education\n",
    "#college park scholars/gemstone/honors - Office of Undergraduate Studies\n",
    "#business/MBA - RH Smith\n",
    "#health - School of Public Health\n",
    "#agri - College of Agriculture and Natural Resources\n",
    "#arts - College of Arts and Humanities\n",
    "#lang/Persian/Russian/Spanish/French/Latin/Portuguese/Korean/Germanic Studies/\n",
    "#Italian/Hebrew/Greek/america- College of Arts and Humanities\n",
    "\n",
    "for i in uniqueCourses:\n",
    "    if i not in final_code_to_school:\n",
    "        matches = find_matching_string(code_fullname_dict[i], majors_schools.keys())\n",
    "        if len(matches) > 0:\n",
    "            final_code_to_school[i] = majors_schools[matches[0]]\n",
    "        else: #now will need to match keywords of major name to school\n",
    "            if any(x in code_fullname_dict[i].lower() for x in ['biolog', 'systematics', 'biom', 'machine']):\n",
    "                final_code_to_school[i] = 'CMNS'\n",
    "            elif 'engineer' in code_fullname_dict[i].lower():\n",
    "                final_code_to_school[i] = 'ENGR'\n",
    "            elif any(x in code_fullname_dict[i].lower() for x in ['ed', 'teach']):\n",
    "                final_code_to_school[i] = 'EDUC'\n",
    "            elif any(x in code_fullname_dict[i].lower() for x in ['college park scholars', 'gemstone', 'honors', 'first-year', 'aces', 'civicus', 'design cultures', 'university', 'global', 'maryland']):\n",
    "                final_code_to_school[i] = 'Office of Undergraduate Studies'\n",
    "            elif any(x in code_fullname_dict[i].lower() for x in ['business', 'mba', 'accounting', 'entrepreneur', 'manage', 'decision']):\n",
    "                final_code_to_school[i] = 'BMGT'\n",
    "            elif any(x in code_fullname_dict[i].lower() for x in ['theatre', 'film','lang','latin', 'germanic', 'immigration', 'art', 'gay']):\n",
    "                final_code_to_school[i] = 'ARHU'\n",
    "            elif any(x in code_fullname_dict[i].lower() for x in ['health', 'epid']):\n",
    "                final_code_to_school[i] = 'SPHL'\n",
    "            elif any(x in code_fullname_dict[i].lower() for x in ['behavior', 'law']):\n",
    "                final_code_to_school[i] = 'BSOS'\n",
    "            elif 'information' in code_fullname_dict[i].lower():\n",
    "                final_code_to_school[i] = 'INFO'\n",
    "            elif 'urban' in code_fullname_dict[i].lower(): #architecture\n",
    "                final_code_to_school[i] = 'ARCH'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in uniqueCourses:\n",
    "    if i not in final_code_to_school:\n",
    "        print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_code_dept = pd.DataFrame.from_dict(final_code_to_school, orient='index').reset_index(names='Major').rename(columns={0:'Department'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Major</th>\n",
       "      <th>Department</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>BMAC</td>\n",
       "      <td>BMGT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>PMAM</td>\n",
       "      <td>ENGR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Z115</td>\n",
       "      <td>ENGR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ENAE</td>\n",
       "      <td>ENGR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>PMAE</td>\n",
       "      <td>ENGR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>417</th>\n",
       "      <td>CPPL</td>\n",
       "      <td>Office of Undergraduate Studies</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>418</th>\n",
       "      <td>ENBC</td>\n",
       "      <td>ENGR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>419</th>\n",
       "      <td>SLAA</td>\n",
       "      <td>ARHU</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>420</th>\n",
       "      <td>CPET</td>\n",
       "      <td>Office of Undergraduate Studies</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>421</th>\n",
       "      <td>KORA</td>\n",
       "      <td>ARHU</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>422 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Major                       Department\n",
       "0    BMAC                             BMGT\n",
       "1    PMAM                             ENGR\n",
       "2    Z115                             ENGR\n",
       "3    ENAE                             ENGR\n",
       "4    PMAE                             ENGR\n",
       "..    ...                              ...\n",
       "417  CPPL  Office of Undergraduate Studies\n",
       "418  ENBC                             ENGR\n",
       "419  SLAA                             ARHU\n",
       "420  CPET  Office of Undergraduate Studies\n",
       "421  KORA                             ARHU\n",
       "\n",
       "[422 rows x 2 columns]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_code_dept"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Missing Professors <a class=\"anchor\" id = \"missing-professors\"></a>\n",
    "\n",
    "Now that we have a dataframe that can store what each department each class is listed under, we can look for potnetial missed matches. We use the following method to generate a dataframe of potential matches using the criteria defined above, where a person is a potential match if the PlanetTerp first or last name is somewhere within the Diamondback name and they are listed in the Diamondback as working in the department that the classes they taught on PlanetTerp are under. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "majors_df = df_code_dept\n",
    "\n",
    "def find_similar(first, last, courses, outer):\n",
    "    c = []\n",
    "    # find the department that the major is listed under\n",
    "    for i, course in enumerate(courses.replace(\"'\", \"\")[1:-1].split(\", \")):\n",
    "        index = majors_df.index[majors_df['Major'] == course[:4]].to_list()\n",
    "        if index != []:\n",
    "            temp = majors_df.at[index[0], \"Department\"]\n",
    "            if len(temp) == 4:\n",
    "                c.append(temp)\n",
    "            elif temp == 'Public Policy':\n",
    "                c.append('PLCY')\n",
    "    print(c)\n",
    "    # separates out hyphenated last names\n",
    "    names = [first, last]\n",
    "    if \"-\" in last:\n",
    "        names.append(last.split(\"-\")[0])\n",
    "        names.append(last.split(\"-\")[1])\n",
    "\n",
    "    # looks for professors that match our criteria\n",
    "    df = outer.loc[(outer[\"_merge\"] != \"left_only\") & \n",
    "                   ((outer[\"first_name\"].isin(names)) |\n",
    "                    (outer[\"last_name\"].isin(names))\n",
    "                    )][[\"real_name(s)\", \"years_taught\", \"departments\", \"name\"]]\n",
    "    df = df[df['departments'].str.contains('|'.join(c))]\n",
    "    df = df.sort_values('real_name(s)', ascending=True)\n",
    "    bad_dep = [\"VPSA\", \"VPAF\", \"SVPA\", \"PRES\", \"VPAA\", \"LIBR\", \"VPA-\", \"DIT-\", \n",
    "               \"VPR-\", \"IT-N\", \"VPUR\", \"IT-I\"]\n",
    "    # drops potential matches belonging to \"bad departments\", essentially those who don't teach\n",
    "    for i, row in df.iterrows():\n",
    "        for dep in bad_dep:\n",
    "            if dep in row[\"departments\"]:\n",
    "                df.drop(i, inplace = True)\n",
    "                break\n",
    "    return df.reset_index().drop(\"index\", axis = 1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From here, we now have a user based confirmation system. The code will display all of the potential matches detected by method above for each of the 655 missing PlanetTerp professors, prompting the user to either confirm that none of the potential matches are the person we are looking for or give the index in the dataframe of the correct match."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "#left_copy = left_only.copy() # uncomment this when you want to start over\n",
    "#left_rename = pd.DataFrame(columns = left_copy.columns)  # uncomment this when you want to start over\n",
    "\n",
    "left_copy = pd.read_csv(f'src/2_clean_data/left_remaining.csv') # uncomment this if you want to continue where you left off\n",
    "left_rename = pd.read_csv(f'src/2_clean_data/renamed_lefts.csv') # uncomment this if you want to continue where you left off\n",
    "\n",
    "\n",
    "responses = [\"n\",\"no\", \"\"]\n",
    "\n",
    "# go 10 at a time, saving progress each time\n",
    "for i, row in left_copy.head(10).iterrows():\n",
    "    first = row[\"name\"].split()[0]\n",
    "    last =  row[\"name\"].split()[1]\n",
    "    # the courses taught and semesters they taught in are displayed to better help decided if potential matches are\n",
    "    # actually the same person\n",
    "    print(row[\"course\"])\n",
    "    print(row[\"semester\"])\n",
    "    similar = find_similar(first,last,row[\"course\"], outer)\n",
    "    if similar.empty == False:      \n",
    "        display(HTML(similar.to_html()))\n",
    "        response = input(f\"{first} {last}: \")\n",
    "        # if the user confirms no matches, we move on\n",
    "        if (response in responses):\n",
    "            left_copy.drop(i, inplace = True)\n",
    "        # if the user confirms a match, the match is recorded and renamed so that it can then be joined later\n",
    "        else:\n",
    "            left_copy.loc[i, 'name'] = similar.loc[int(response), 'name']\n",
    "            left_rename = left_rename.append(left_copy.loc[i], ignore_index=True)\n",
    "            left_copy.drop(i, inplace = True)\n",
    "    else:\n",
    "        left_copy.drop(i, inplace = True)\n",
    "\n",
    "    clear_output()\n",
    "\n",
    "if os.path.exists(\"src/2_clean_data/renamed_lefts.csv\") == False and os.path.exists(\"src/2_clean_data/left_remaining.csv\") == False:\n",
    "    left_rename.to_csv('src/2_clean_data/renamed_lefts.csv', index = False)\n",
    "    left_copy.to_csv(f'src/2_clean_data/left_remaining.csv', index=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the end, we only found 2 matches using this system. These were Ebonie Cooper-Jean and Naghmeh Momeni, who were both listed in the Diamondback with last names that were slightly different than what was listed on PlanetTerp. The other 653 PlanetTerp professors were either Ph. D. candidates, graduate teaching assistants, assistant professors, or lecturers, none of which are listed in the Diamondback. As such, these data points were dropped, and the 2 matches that we were able to find were added to our database."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Professors with Missing Years <a class=\"anchor\" id = \"professors-with-missing-years\"></a>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another thing that we have to consider is professors who are listed as having taught in a specific year on PlanetTerp, but lack salary data in the Diamondback. To solve this, we looked for any professor that matched these conditions in our combined data. We then can use the same method from before, where users were prompted with a list of potential matches and could confirm whether or not there were any actual matches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_data = pd.read_csv(f'src/2_clean_data/combined_data_remaining.csv', converters={'years_taught': ast.literal_eval, 'semester': ast.literal_eval,'course': ast.literal_eval, 'salaries': ast.literal_eval, 'departments': ast.literal_eval})\n",
    "#combined_data = pd.read_csv(f'combined_data.csv')\n",
    "salary_data = pd.read_csv(f'src/2_clean_data/clean_salary_data.csv', converters={'years_taught': ast.literal_eval, 'salaries': ast.literal_eval, 'departments': ast.literal_eval})\n",
    "new_combine = pd.read_csv(f'src/2_clean_data/new_combined_data.csv', converters={'years_taught': ast.literal_eval, 'salaries': ast.literal_eval, 'departments': ast.literal_eval})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, row in combined_data.head(100).iterrows():\n",
    "    semesters = row['semester']\n",
    "    missing = []\n",
    "    for sem in semesters:\n",
    "        year = int(sem[-5:])\n",
    "        if \"fall\" in sem: \n",
    "            year += 1\n",
    "        if year >= 2013 and year <= 2022 and (not year in row[\"years_taught\"]) :\n",
    "            if not year in missing:\n",
    "                missing.append(year)\n",
    "    if len(missing) >  0:\n",
    "        first = row[\"name\"].split(\" \")[0]\n",
    "        last = row[\"name\"].split(\" \")[1]\n",
    "        count +=1\n",
    "        similar = find_similar(first,last,row[\"course\"], salary_data, year)\n",
    "        if len(similar) >= 1:\n",
    "            years = row[\"years_taught\"].copy()\n",
    "            years.sort()\n",
    "            missing.sort()\n",
    "            print(f\"years: {years}\")\n",
    "            print(f\"missing years: {missing}\")\n",
    "            display(HTML(similar.to_html()))\n",
    "            response = input(f\"{first} {last}: \")\n",
    "            if (not response in responses):\n",
    "                new_years = similar.loc[int(response), 'years_taught']\n",
    "                combined_data.loc[i, 'years_taught'].extend(new_years)\n",
    "\n",
    "                new_salaries = similar.loc[int(response), 'salaries']\n",
    "                combined_data.loc[i, 'salaries'].extend(new_salaries)\n",
    "\n",
    "                new_departments = similar.loc[int(response), 'departments']\n",
    "                combined_data.loc[i, 'departments'].extend(new_departments)\n",
    "\n",
    "                new_combine = new_combine.append(combined_data.loc[i], ignore_index=True)\n",
    "            clear_output()\n",
    "    combined_data.drop(i, inplace = True)\n",
    "\n",
    "if os.path.exists(\"src/2_clean_data/combined_data_remaining.csv\") == False and os.path.exists(\"src/2_clean_data/new_combined_data.csv\") == False:\n",
    "    combined_data.to_csv('combined_data_remaining.csv', index=False)\n",
    "    new_combine.to_csv('new_combined_data.csv', index = False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We found much greater success here than in our previous attempt at finding missing professors. We were able to find 30 matches this time, with the majority being people changing their names to their nicknames in the Diamondback database. This included going from Christopher to Chris, William to Bill, and Laurence to Larry. As for the rest of the professors who are lacking salary data in a year they are recorded as having taught, it seems like one possibility is a professor who stopped teaching halfway through the year. It seems like a professor's salary data is only listed on the Diamondback if they worked the full year, so someone teaching in the fall semester and then leaving for whatever reason would not show up. Other than that, it is possible that a student left their review a long time after they took a course, leading their review to be flagged under a semester that the professor didn't actually teach in. Either way, these data points will be dropped in the future, and our data will be fully matched."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(f'src/2_clean_data/combined_data.csv')\n",
    "changed_names = pd.read_csv(f'src/2_clean_data/new_combined_data.csv')\n",
    "\n",
    "df = df.drop(df[df['name'] == \"P KSHETRY\"].index)\n",
    "df = df.drop(df[df['name'] == \"R APTER\"].index)\n",
    "\n",
    "for i, row in changed_names.iterrows():\n",
    "    df = df.drop(df[df['name'] == row['name']].index)\n",
    "\n",
    "result = pd.concat([df, changed_names], axis=0)\n",
    "result = result.reset_index(drop=True)\n",
    "\n",
    "if os.path.exists(\"src/2_clean_data/final_combine_data.csv\") == False:\n",
    "    result.to_csv('src/2_clean_data/final_combine_data.csv', index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

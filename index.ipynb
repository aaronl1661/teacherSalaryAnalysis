{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Title\n",
    "Collaborators: Albert Chen, Alex Chen, Aaron Lin, Srujan Penikelapati"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "\n",
    "Faculty are the lifeblood of any university. They conduct cutting-edge research to discover new insights that push the boundary of the field they are studying. They also teach classes, helping students learn new skills and knowledge that will benefit them in their professional lives. As in any occupation, professors vary in the quality of their research and their teaching ability, which directly impacts the quality of education that students who take their classes receive.\n",
    "\n",
    "Students understand the fact that their choice of professor for a course can be the difference between an engaging, informative semester or a less than pleasing experience. Prior to registration, students often check professor reviews, online posts regarding the class, grade distributions, and other sources of information to determine whose class to choose. \n",
    "\n",
    "The goal of this project is to see the connection between how effective a professor is and possible determining factors of their teaching ability. Using data science, we will review salary data, years of experience, and average student rating of professors here at the University of Maryland to see how they correlate with their average Grade Point Average (GPA) for students across their classes. For example, does a professor with a high salary and many years of experience at UMD reflect in higher student GPAs? Once we build a correlative model, we can also pose performative questions in reverse, like whether the University is getting the best 'bang-for-their-buck' given a professor's salary and their average GPA as compared to other professors in the same field. \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Collection\n",
    "\n",
    "We first need to collect data that is relevant to our study. To get grade distributions and student reviews, we made GET requests to the [PlanetTerp API](https://planetterp.com/api/) and stored the data in dataframes. To get information on a professor's salaries and how long the've been teaching, we made GET requests to the [Diamondback API](https://api.dbknews.com/docs/#/salary) and also stored that data in a dataframe. However, performing all of these requests can take a long time, making it impractical to work efficiently. As such, we stored our dataframes into various .csv files. This also means that our data is accurate up to April 28th, 2023, as from there on we read from our csv files instead of requesting from the websites themselves. The code used for that is below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "import os\n",
    "from pathlib import Path\n",
    "import os.path\n",
    "from statsmodels.formula.api import *\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import linear_model\n",
    "from ggplot import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "grades_exist = os.path.exists(\"src/1_collect_data/planet_terp_data/PT_grade_data.csv\")\n",
    "reviews_exist = os.path.exists(\"src/1_collect_data/planet_terp_data/PT_review_data.csv\")\n",
    "salaries_exist = os.path.exists(\"src/1_collect_data/salary_data/DB_combined_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "if reviews_exist == False:\n",
    "    reviews = []\n",
    "    done = False\n",
    "    offset = 0\n",
    "    while done == False:\n",
    "        r = requests.get(\"https://planetterp.com/api/v1/professors\", params = {\"offset\":offset, \"reviews\": \"true\", \"limit\":100},)\n",
    "        if r.json() == []:\n",
    "            done = True\n",
    "        else:\n",
    "            reviews.append(r.json())\n",
    "            offset = offset+100\n",
    "    df = pd.DataFrame()\n",
    "    count = 0\n",
    "    for i in reviews:\n",
    "        for j in i:\n",
    "            if j.get(\"reviews\") != []:\n",
    "                for k in j.get(\"reviews\"):\n",
    "                    if k.get(\"course\") != None and j.get(\"type\") == \"professor\":\n",
    "                        df.at[count, \"name\"] = j.get(\"name\")\n",
    "                        df.at[count, \"slug\"] = j.get(\"slug\")\n",
    "                        df.at[count, \"type\"] = j.get(\"type\")\n",
    "                        df.at[count, \"course\"] = k.get(\"course\")\n",
    "                        df.at[count, \"rating\"] = k.get(\"rating\")\n",
    "                        df.at[count, \"review\"] = k.get(\"review\")\n",
    "                        df.at[count, \"date\"] = k.get(\"created\")[:10]\n",
    "                        count = count + 1\n",
    "\n",
    "    df = df.sort_values(by=[\"name\",\"course\"])\n",
    "    df.to_csv(\"src/1_collect_data/PT_review_data.csv\", encoding='utf-8', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "if grades_exist == False:\n",
    "    grades = []\n",
    "    professors = df[\"name\"].drop_duplicates()\n",
    "    for prof in professors:\n",
    "        r = requests.get(\"https://planetterp.com/api/v1/grades\", params = {\"offset\":offset, \"reviews\": \"true\", \"limit\":100, \"professor\": prof})\n",
    "        grades.append(r.json())\n",
    "    grade_df = pd.DataFrame()\n",
    "    count = 0\n",
    "    for i in grades:\n",
    "        if i != []:\n",
    "            for j in i:\n",
    "                grade_df.at[count, \"professor\"] = j.get(\"professor\")\n",
    "                grade_df.at[count, \"course\"] = j.get(\"course\")\n",
    "                grade_df.at[count, \"semester\"] = j.get(\"semester\")\n",
    "                grade_df.at[count, \"section\"] = j.get(\"section\")\n",
    "                grade_df.at[count, \"A+\"] = j.get(\"A+\")\n",
    "                grade_df.at[count, \"A\"] = j.get(\"A\")\n",
    "                grade_df.at[count, \"A-\"] = j.get(\"A-\")\n",
    "                grade_df.at[count, \"B+\"] = j.get(\"B+\")\n",
    "                grade_df.at[count, \"B\"] = j.get(\"B\")\n",
    "                grade_df.at[count, \"B-\"] = j.get(\"B-\")\n",
    "                grade_df.at[count, \"C+\"] = j.get(\"C+\")\n",
    "                grade_df.at[count, \"C\"] = j.get(\"C\")\n",
    "                grade_df.at[count, \"C-\"] = j.get(\"C-\")\n",
    "                grade_df.at[count, \"D+\"] = j.get(\"D+\")\n",
    "                grade_df.at[count, \"D\"] = j.get(\"D\")\n",
    "                grade_df.at[count, \"D-\"] = j.get(\"D-\")\n",
    "                grade_df.at[count, \"F\"] = j.get(\"F\")\n",
    "                grade_df.at[count, \"W\"] = j.get(\"W\")\n",
    "                grade_df.at[count, \"Other\"] = j.get(\"Other\")\n",
    "                count = count + 1\n",
    "                print(j.get(\"professor\"))\n",
    "    \n",
    "    grade_df = grade_df.sort_values(by=[\"professor\",\"course\"])\n",
    "    grade_df.to_csv(\"src/1_collect_data/PT_grade_data.csv\", encoding = \"utf-8\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine(group):\n",
    "    years = group['year'].tolist()\n",
    "    salaries = group['Salary'].tolist()\n",
    "    salaries = [float(s.replace(\",\",\"\")[1:]) for s in salaries]\n",
    "    departments = group['Department'].tolist()\n",
    "    \n",
    "    i = 0\n",
    "    while i < len(years) - 1:\n",
    "        if (years[i] == years[i+1]):\n",
    "            if salaries[i] != salaries[i + 1]:\n",
    "                salaries[i] = salaries[i] + salaries[i + 1]\n",
    "            years.pop(i+1)\n",
    "            salaries.pop(i+1)\n",
    "            departments.pop(i+1)\n",
    "        else:\n",
    "            i += 1\n",
    "\n",
    "    return pd.Series({\n",
    "        'years_taught': years,\n",
    "        'salaries': salaries,\n",
    "        'departments': departments,\n",
    "    })\n",
    "\n",
    "if salaries_exist == False:\n",
    "    # get years that api is valid for\n",
    "    r_years = requests.get(\"https://api.dbknews.com/salary/years\")\n",
    "    years = r_years.json()[\"data\"]\n",
    "\n",
    "    df = pd.DataFrame()\n",
    "\n",
    "    # for each year, get salary data\n",
    "    for year in years:\n",
    "        r = requests.get(f\"https://api.dbknews.com/salary/year/{year}\")\n",
    "\n",
    "        # number of faculty\n",
    "        count = r.json()[\"count\"]\n",
    "        year_df = pd.DataFrame()\n",
    "        page = 0\n",
    "\n",
    "        while page * 10 < count:\n",
    "            page += 1\n",
    "\n",
    "            # get salary data for 1 page\n",
    "            r = requests.get(f\"https://api.dbknews.com/salary/year/{year}?page={page}\")\n",
    "            page_df = pd.DataFrame.from_dict(r.json()[\"data\"])\n",
    "\n",
    "            # remove division and title columns, modify department col, and add year\n",
    "            page_df = page_df.drop(['Division', \"Title\"], axis=1)\n",
    "            page_df[\"Department\"] = page_df[\"Department\"].str.slice(stop=4)\n",
    "            page_df[\"year\"] = [f\"{year}\"] * len(page_df.index)\n",
    "            year_df = pd.concat([year_df, page_df], axis=0)\n",
    "\n",
    "        print(f\"year {year} finished\")\n",
    "        year_df.to_csv(f'src/1_collect_data/salary_data/{year}data.csv', index=False)\n",
    "\n",
    "    for year in years:\n",
    "        year_df = pd.read_csv(f'src/1_collect_data/salary_data/{year}data.csv')\n",
    "        year_df['Employee'] = year_df['Employee'].str.replace('\\n', ' ')\n",
    "        df = pd.concat([df, year_df], axis=0)\n",
    "\n",
    "    df_grouped = df.groupby(['Employee']).apply(combine).reset_index()\n",
    "\n",
    "    df_grouped['name'] = df_grouped['Employee'].apply(lambda x: (x.split(', ')[1].split(\" \")[0]+ ' ' + x.split(', ')[0].split(\" \")[-1]).upper())\n",
    "\n",
    "    print(df_grouped.to_string())\n",
    "    df_grouped.to_csv(f'src/1_collect_data/salary_data/DB_combined_data.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews_df = pd.read_csv(\"src/1_collect_data/planet_terp_data/PT_review_data.csv\")\n",
    "grades_df = pd.read_csv(\"src/1_collect_data/planet_terp_data/PT_grade_data.csv\")\n",
    "salaries_df = pd.read_csv(\"src/1_collect_data/salary_data/DB_combined_data.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
